{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "API = \"http://gustav1.ux.uis.no:5002\"\n",
    "\n",
    "QUERY_FILE = \"data/queries.txt\"\n",
    "QRELS_FILE = \"data/qrels.csv\"\n",
    "TITLE_OUTPUT_FILE = \"data/baseline_title.txt\"\n",
    "CONTENT_OUTPUT_FILE = \"data/baseline_content.txt\"\n",
    "ANCHORS_OUTPUT_FILE = \"data/baseline_anchors.txt\"\n",
    "\n",
    "# load queries\n",
    "queries = {}\n",
    "with open(QUERY_FILE, \"r\") as fin:\n",
    "    for line in fin.readlines():\n",
    "        qid, query = line.strip().split(\" \", 1)\n",
    "        queries[qid] = query\n",
    "        \n",
    "# load given ground truth\n",
    "gtruth = {}\n",
    "with open(QRELS_FILE, 'r') as qr:\n",
    "    for line in qr.readlines():\n",
    "        if line.startswith('QueryId'):\n",
    "            continue\n",
    "        qid, did, rel = line.strip().split(',')\n",
    "        if qid not in gtruth:\n",
    "            gtruth[qid] = {}\n",
    "        gtruth[qid][did] = int(rel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(indexname, query, field, size=10):\n",
    "    url = \"/\".join([API, indexname, \"_search\"]) + \"?\" \\\n",
    "          + urllib.parse.urlencode({\"q\": query, \"df\": field, \"size\": size})\n",
    "    response = requests.get(url).text\n",
    "    return json.loads(response)\n",
    "\n",
    "\n",
    "def termvectors(indexname, docid, term_statistics=\"true\"): \n",
    "    url = \"/\".join([API, indexname, docid, \"_termvectors\"]) + \"?\" \\\n",
    "          + urllib.parse.urlencode({\"term_statistics\": term_statistics})\n",
    "    response = requests.get(url).text\n",
    "    return json.loads(response)\n",
    "\n",
    "def exists(indexname, docid): \n",
    "    url = \"/\".join([API, indexname, docid, \"_exists\"])\n",
    "    response = requests.get(url).text\n",
    "    return json.loads(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcg(rel, p):\n",
    "    dcg = rel[0]\n",
    "    for i in range(1, min(p, len(rel))): \n",
    "        dcg += rel[i] / math.log(i + 1, 2)  # rank position is indexed from 1..\n",
    "    return dcg\n",
    "\n",
    "\n",
    "def evaluate(rankings, gtruth, df):\n",
    "    sum_ndcg10 = 0\n",
    "    sum_ndcg20 = 0\n",
    "    \n",
    "    for qid, ranking in sorted(rankings.items()):\n",
    "        gt = gtruth[qid]    \n",
    "        # print(\"\\nQuery\", qid)\n",
    "\n",
    "        # relevance levels of our ranking\n",
    "        gains = []\n",
    "        for doc_id in ranking: \n",
    "            if gt.get(doc_id, 0) >= 0:\n",
    "                gains.append(gt.get(doc_id, 0))\n",
    "            else: \n",
    "                gains.append(0)\n",
    "        \n",
    "        # print(\"Gains:\", gains)\n",
    "\n",
    "        # relevance levels of the idealized ranking\n",
    "        gain_ideal = sorted([v for _, v in gt.items()], reverse=True)\n",
    "\n",
    "        ndcg10 = dcg(gains, 10) / dcg(gain_ideal, 10)\n",
    "        ndcg20 = dcg(gains, 20) / dcg(gain_ideal, 20)\n",
    "        sum_ndcg10 += ndcg10\n",
    "        sum_ndcg20 += ndcg20\n",
    "\n",
    "        # print(\"NDCG@10:\", round(ndcg10, 3), \"\\nNDCG@20:\", round(ndcg20, 3))\n",
    "\n",
    "    print(\"\\nAverage (%s):\" % df)\n",
    "    print(\"\\tNDCG@10:\", round(sum_ndcg10 / len(rankings), 3), \"\\n\\tNDCG@20:\", round(sum_ndcg20 / len(rankings), 3), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "Search, load given ground trouth, evaluate: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching title field . . . \n",
      "Done searching title field!\n",
      "\n",
      "Average (title):\n",
      "\tNDCG@10: 0.128 \n",
      "\tNDCG@20: 0.114 \n",
      "\n",
      "Searching content field . . . \n",
      "Done searching content field!\n",
      "\n",
      "Average (content):\n",
      "\tNDCG@10: 0.138 \n",
      "\tNDCG@20: 0.128 \n",
      "\n",
      "Searching anchors field . . . \n",
      "Done searching anchors field!\n",
      "\n",
      "Average (anchors):\n",
      "\tNDCG@10: 0.057 \n",
      "\tNDCG@20: 0.042 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def title_search_evaluate():    \n",
    "    # search title field\n",
    "    print(\"Searching title field . . . \")\n",
    "    with open(TITLE_OUTPUT_FILE, \"w\") as fin:\n",
    "        fin.write(\"QueryId,DocumentId\")\n",
    "        for qid, query in queries.items():\n",
    "            res = search(\"clueweb12b\", query, \"title\", size=20)\n",
    "            for r in res.get(\"hits\", {}).get(\"hits\", {}):\n",
    "                fin.write(\"\\n{},{}\".format(qid, r[\"_id\"]))\n",
    "    print(\"Done searching title field!\")\n",
    "    # load rankings for title field search\n",
    "    rankings_title = {}\n",
    "    with open(TITLE_OUTPUT_FILE, \"r\") as fin:\n",
    "        docs = []\n",
    "        for line in fin.readlines():\n",
    "            if line.startswith('QueryId'):\n",
    "                continue\n",
    "            qid, doc_id = line.strip().split(\",\")\n",
    "            if qid not in rankings_title: \n",
    "                rankings_title[qid] = []\n",
    "            rankings_title[qid].append(doc_id)\n",
    "    # evaluate\n",
    "    evaluate(rankings_title, gtruth, \"title\")\n",
    "\n",
    "    \n",
    "def content_search_evaluate():\n",
    "    # search content field\n",
    "    print(\"Searching content field . . . \")\n",
    "    with open(CONTENT_OUTPUT_FILE, \"w\") as fin:\n",
    "        fin.write(\"QueryId,DocumentId\")\n",
    "        for qid, query in queries.items():\n",
    "            res = search(\"clueweb12b\", query, \"content\", size=20)\n",
    "            for r in res.get(\"hits\", {}).get(\"hits\", {}):\n",
    "                fin.write(\"\\n{},{}\".format(qid, r[\"_id\"]))\n",
    "    print(\"Done searching content field!\")\n",
    "    # load rankings for content field search\n",
    "    rankings_content = {}\n",
    "    with open(CONTENT_OUTPUT_FILE, \"r\") as fin:\n",
    "        docs = []\n",
    "        for line in fin.readlines():\n",
    "            if line.startswith('QueryId'):\n",
    "                continue\n",
    "            qid, doc_id = line.strip().split(\",\")\n",
    "            if qid not in rankings_content: \n",
    "                rankings_content[qid] = []\n",
    "            rankings_content[qid].append(doc_id)\n",
    "    # evaluate\n",
    "    evaluate(rankings_content, gtruth, \"content\")\n",
    "    \n",
    "\n",
    "def anchors_search_evaluate():\n",
    "    # search anchors field\n",
    "    print(\"Searching anchors field . . . \")\n",
    "    with open(ANCHORS_OUTPUT_FILE, \"w\") as fin:\n",
    "        fin.write(\"QueryId,DocumentId\")\n",
    "        for qid, query in queries.items():\n",
    "            res = search(\"clueweb12b_anchors\", query, \"anchors\", size=20)\n",
    "            for r in res.get(\"hits\", {}).get(\"hits\", {}):\n",
    "                # check if present in clueweb12b\n",
    "                time.sleep(0.25)\n",
    "                # res_check = termvectors(\"clueweb12b\", str(r[\"_id\"]))\n",
    "                if exists(\"clueweb12b\", r[\"_id\"])[\"exists\"] == True:\n",
    "                    fin.write(\"\\n{},{}\".format(qid, r[\"_id\"]))\n",
    "                else: \n",
    "                    continue\n",
    "    print(\"Done searching anchors field!\")\n",
    "    # load rankings for anchors field search\n",
    "    rankings_anchors = {}\n",
    "    with open(ANCHORS_OUTPUT_FILE, \"r\") as fin:\n",
    "        docs = []\n",
    "        for line in fin.readlines():\n",
    "            if line.startswith('QueryId'):\n",
    "                continue\n",
    "            qid, doc_id = line.strip().split(\",\")\n",
    "            if qid not in rankings_anchors:\n",
    "                rankings_anchors[qid] = []\n",
    "            rankings_anchors[qid].append(doc_id)\n",
    "    # evaluate\n",
    "    evaluate(rankings_anchors, gtruth, \"anchors\")\n",
    "\n",
    "title_search_evaluate()\n",
    "content_search_evaluate()\n",
    "anchors_search_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs:\n",
    "\n",
    "- Retrieve results for all queries (in `data/queries.txt`)\n",
    "- Do it for both `title` and `content` fields (separately) and write the output to files\n",
    "- Evaluate the results against the relevance judgments (in `data/qrels.csv`) in terms of NDCG@10 and NDCG@20\n",
    "\n",
    "- NB! `anchors` field retrieval is also done in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
