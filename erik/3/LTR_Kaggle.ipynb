{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment 3 - Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "API = \"http://gustav1.ux.uis.no:5002\"\n",
    "\n",
    "FIELD_MOD = {\n",
    "    1: [\"title\", \"BM25\"],\n",
    "    2: [\"title\", \"LM\"],\n",
    "    3: [\"content\", \"BM25\"],\n",
    "    4: [\"content\", \"LM\"],\n",
    "    5: [\"anchors\", \"BM25\"],\n",
    "    6: [\"anchors\", \"LM\"]\n",
    "}\n",
    "\n",
    "BASIC_INDEX_NAME = \"clueweb12b\"\n",
    "ANCHORS_INDEX_NAME = \"clueweb12b_anchors\"\n",
    "\n",
    "CACHE_DIR = \"cache\"\n",
    "CACHE_DIR_SEARCH = CACHE_DIR + \"/search\"\n",
    "CACHE_DIR_TERMVECTORS = CACHE_DIR + \"/termvectors\"\n",
    "\n",
    "LAMBDA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_queries(query_file):\n",
    "    queries = {}\n",
    "    with open(query_file, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            qid, query = line.strip().split(\" \", 1)\n",
    "            queries[qid] = query\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading features file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_features(features_file):\n",
    "    X, y, qids, doc_ids = [], [], [], []\n",
    "    with open(features_file, \"r\") as f:\n",
    "        i, s_qid = 0, None\n",
    "        for line in f:\n",
    "            items = line.strip().split()\n",
    "            label = int(items[0])\n",
    "            qid = items[1]\n",
    "            doc_id = items[2]\n",
    "            features = np.array([float(i.split(\":\")[1]) for i in items[3:]])\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "            qids.append(qid)\n",
    "            doc_ids.append(doc_id)\n",
    "\n",
    "    return X, y, qids, doc_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(indexname, query, field, size=10):\n",
    "    cache_file = CACHE_DIR_SEARCH + \"/\" + indexname + \"_\" + query + \"_\" + field + \"_\" + str(size)\n",
    "    url = \"/\".join([API, indexname, \"_search\"]) + \"?\" \\\n",
    "          + urllib.parse.urlencode({\"q\": query, \"df\": field, \"size\": size})\n",
    "    if os.path.exists(cache_file):  # return from cache\n",
    "        with open(cache_file) as infile:\n",
    "            response = json.load(infile)\n",
    "            return json.loads(response)\n",
    "    else:\n",
    "        with open(cache_file, \"w\") as outfile:\n",
    "            response = requests.get(url).text\n",
    "            json.dump(response, outfile)\n",
    "            return json.loads(response)\n",
    "\n",
    "def termvectors(indexname, docid, term_statistics=\"true\"): \n",
    "    cache_file = CACHE_DIR_TERMVECTORS + \"/\" + indexname + \"_\" + docid + \"_\" + term_statistics\n",
    "    url = \"/\".join([API, indexname, docid, \"_termvectors\"]) + \"?\" \\\n",
    "          + urllib.parse.urlencode({\"term_statistics\": term_statistics})\n",
    "    if os.path.exists(cache_file):  # return from cache\n",
    "        with open(cache_file) as infile:\n",
    "            response = json.load(infile)\n",
    "            return json.loads(response)\n",
    "    else:\n",
    "        with open(cache_file, \"w\") as outfile:\n",
    "            response = requests.get(url).text\n",
    "            json.dump(response, outfile)\n",
    "            return json.loads(response)\n",
    "\n",
    "def analyze_query(indexname, query):\n",
    "    url = \"/\".join([API, indexname, \"_analyze\"]) + \"?\" \\\n",
    "          + urllib.parse.urlencode({\"text\": query})\n",
    "    response = json.loads(requests.get(url).text)\n",
    "    tokens = response[\"tokens\"]\n",
    "    query_terms = []\n",
    "    for t in sorted(tokens, key=lambda x: x[\"position\"]):\n",
    "        query_terms.append(t[\"token\"])\n",
    "    return query_terms\n",
    "\n",
    "def exists(indexname, docid): \n",
    "    url = \"/\".join([API, indexname, docid, \"_exists\"])\n",
    "    response = requests.get(url).text\n",
    "    return json.loads(response)\n",
    "\n",
    "def get_index_name(field):\n",
    "    return ANCHORS_INDEX_NAME if field == \"anchors\" else BASIC_INDEX_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CollectionLM(object):\n",
    "    def __init__(self, qterms):\n",
    "        self._probs = {}\n",
    "        # computing P(t|C_i) for each field and for each query term\n",
    "        for fid in FIELD_MOD:\n",
    "            self._probs[FIELD_MOD[fid][0]] = {}\n",
    "            for t in qterms:\n",
    "                self._probs[FIELD_MOD[fid][0]][t] = self.__get_prob(FIELD_MOD[fid][0], t)\n",
    "\n",
    "    def __get_prob(self, field, term):\n",
    "        # use a boolean query to find a document that contains the term\n",
    "        index_name = get_index_name(field)\n",
    "        hits = search(index_name, term, field, size=1).get(\"hits\", {}).get(\"hits\", {})\n",
    "        doc_id = hits[0][\"_id\"] if len(hits) > 0 else None\n",
    "        if doc_id is not None:\n",
    "            # ask for global term statistics when requesting the term vector of that doc (`term_statistics=True` by default)\n",
    "            if termvectors(\"clueweb12b\", doc_id)[\"found\"] == True:\n",
    "                index_name = get_index_name(field)\n",
    "                tv = termvectors(index_name, doc_id)\n",
    "                ttf = tv[\"term_vectors\"][field][\"terms\"].get(term, {}).get(\"ttf\", 0)  # total term count in the collection (in that field)\n",
    "                sum_ttf = tv[\"term_vectors\"][field][\"field_statistics\"][\"sum_ttf\"]\n",
    "                return ttf / sum_ttf\n",
    "\n",
    "        return 0  # this only happens if none of the documents contain that term\n",
    "\n",
    "    def prob(self, field, term):\n",
    "        return self._probs.get(field, {}).get(term, 0)\n",
    "\n",
    "def lm(clm, qterms, doc_id, field):\n",
    "    score = 0  # log P(q|d)\n",
    "    \n",
    "    # Getting term frequency statistics for the given document field from Elasticsearch\n",
    "    # Note that global term statistics are not needed\n",
    "    index_name = get_index_name(field)\n",
    "    tv = termvectors(index_name, doc_id, term_statistics=\"false\")[\"term_vectors\"]\n",
    "\n",
    "    # compute field length $|d|$\n",
    "    len_d = 0  # document field length initialization\n",
    "    if field in tv:  # that document field may be NOT empty\n",
    "        len_d = sum([s[\"term_freq\"] for t, s in tv[field][\"terms\"].items()])\n",
    "        \n",
    "    # scoring the query\n",
    "    for t in qterms:\n",
    "        Pt_theta_d = 0  # P(t|\\theta_d)\n",
    "        if field in tv:\n",
    "            Pt_d = tv[field][\"terms\"].get(t, {}).get(\"term_freq\", 0) / len_d  # $P(t|d)$\n",
    "        else:  # that document field is empty\n",
    "            Pt_d = 0\n",
    "        Pt_C = clm.prob(field, t)  # $P(t|C)$\n",
    "        Pt_theta_d = (1 - LAMBDA) * Pt_d + LAMBDA * Pt_C  # $P(t|\\theta_{d})$ with J-M smoothing\n",
    "        # Pt_theta_d is 0 if t doesn't occur in any doc for that field, even with smoothing:\n",
    "        score += math.log(Pt_theta_d) if Pt_theta_d > 0 else 0  \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointwise LTR class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PointWiseLTRModel(object):\n",
    "    def __init__(self, regressor):\n",
    "        \"\"\"\n",
    "        :param classifier: an instance of scikit-learn regressor\n",
    "        \"\"\"\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def _train(self, X, y):\n",
    "        \"\"\"\n",
    "        Trains and LTR model.\n",
    "        :param X: features of training instances\n",
    "        :param y: relevance assessments of training instances\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert self.regressor is not None\n",
    "        self.model = self.regressor.fit(X, y)\n",
    "\n",
    "    def rank(self, ft, doc_ids):\n",
    "        \"\"\"\n",
    "        Predicts relevance labels and rank documents for a given query\n",
    "        :param ft: a list of features for query-doc pairs\n",
    "        :param ft: a list of document ids\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert self.model is not None\n",
    "        rel_labels = self.model.predict(ft)\n",
    "        sort_indices = np.argsort(rel_labels)[::-1]\n",
    "\n",
    "        results = []\n",
    "        for i in sort_indices:\n",
    "            results.append((doc_ids[i], rel_labels[i]))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(queries):\n",
    "    features = {}\n",
    "\n",
    "    def add_to_features(docid):\n",
    "        if docid not in features[qid]:\n",
    "            features[qid][docid] = {}\n",
    "        features[qid][docid][fid] = r[\"_score\"]\n",
    "\n",
    "    for fid in range(1, len(FIELD_MOD) + 1):\n",
    "        print(\"\\nComputing values for feature '%s & %s' . . .\" % (FIELD_MOD[fid][0], FIELD_MOD[fid][1]))\n",
    "\n",
    "        for qid, query in queries.items():\n",
    "            if qid not in features:\n",
    "                features[qid] = {}\n",
    "\n",
    "            if FIELD_MOD[fid][1] == \"BM25\":\n",
    "                print(\"Query '{0}'\".format(query))\n",
    "                if FIELD_MOD[fid][0] == \"anchors\":\n",
    "                    res = search(\"clueweb12b_anchors\", query, FIELD_MOD[fid][0], size=20)\n",
    "                    for r in res[\"hits\"][\"hits\"]:\n",
    "                        docid = r[\"_id\"]\n",
    "                        if exists(\"clueweb12b\", r[\"_id\"])[\"exists\"] == True:\n",
    "                            add_to_features(docid)\n",
    "                else: \n",
    "                    res = search(\"clueweb12b\", query, FIELD_MOD[fid][0], size=20)                \n",
    "                    for r in res[\"hits\"][\"hits\"]:\n",
    "                        docid = r[\"_id\"]\n",
    "                        add_to_features(docid)\n",
    "            else:  \n",
    "                # LM\n",
    "                print(\"Query '{0}'\".format(query))\n",
    "                if FIELD_MOD[fid][0] == \"anchors\":\n",
    "                    res = search(\"clueweb12b_anchors\", query, FIELD_MOD[fid][0], size=100)\n",
    "                    for r in res[\"hits\"][\"hits\"]:\n",
    "                        docid = r[\"_id\"]\n",
    "                        if exists(\"clueweb12b\", r[\"_id\"])[\"exists\"] == True:\n",
    "                            qterms = analyze_query(\"clueweb12b\", query)\n",
    "                            clm = CollectionLM(qterms)\n",
    "                            scores = {}\n",
    "                            for r in res[\"hits\"][\"hits\"]:\n",
    "                                docid = r[\"_id\"]\n",
    "                                scores[docid] = lm(clm, qterms, docid, FIELD_MOD[fid][0])\n",
    "                            i = 1\n",
    "                            for docid in scores:\n",
    "                                # return top 20\n",
    "                                if i > 20:\n",
    "                                    break\n",
    "                                if docid not in features[qid]:\n",
    "                                    features[qid][docid] = {}\n",
    "                                features[qid][docid][fid] = scores[docid]\n",
    "                                i += 1\n",
    "                else:\n",
    "                    res = search(\"clueweb12b\", query, FIELD_MOD[fid][0], size=100)  # size=100 because of later re-ranking\n",
    "                    qterms = analyze_query(\"clueweb12b\", query)\n",
    "                    clm = CollectionLM(qterms)\n",
    "                    scores = {}\n",
    "                    for r in res[\"hits\"][\"hits\"]:\n",
    "                        docid = r[\"_id\"]\n",
    "                        scores[docid] = lm(clm, qterms, docid, FIELD_MOD[fid][0])\n",
    "                    i = 1\n",
    "                    for docid in scores:\n",
    "                        # return top 20\n",
    "                        if i > 20:\n",
    "                            break\n",
    "                        if docid not in features[qid]:\n",
    "                            features[qid][docid] = {}\n",
    "                        features[qid][docid][fid] = scores[docid]\n",
    "                        i += 1\n",
    "\n",
    "    # additional query features\n",
    "#     print(\"Computing values for additional query features . . .\")\n",
    "#     for qid, query in queries.items():\n",
    "#         avg_arr = []\n",
    "#         for e in features[qid]:\n",
    "#             if 1 in features[qid][e].keys():\n",
    "#                 avg_arr.append(features[qid][e][1])\n",
    "\n",
    "#         for entry in features[qid]:\n",
    "#             ql = len(query.split(' '))\n",
    "#             # hardcoded feature IDs\n",
    "#             features[qid][entry][7] = ql\n",
    "#             features[qid][entry][8] = sum(avg_arr) / len(avg_arr)\n",
    "\n",
    "    # additional document features\n",
    "    print(\"Computing values for additional document features . . .\")\n",
    "    for qid in queries.keys():\n",
    "        for doc_id in features[qid]:\n",
    "            for field in ['title', 'content']:\n",
    "                index_name = get_index_name(field)\n",
    "                try:\n",
    "                    tv = termvectors(index_name, doc_id, term_statistics=\"false\")[\"term_vectors\"]\n",
    "                    if field in tv:\n",
    "                        len_d = sum([s[\"term_freq\"] for t, s in tv[field][\"terms\"].items()])\n",
    "                        if field == 'title':\n",
    "                            features[qid][doc_id][7] = len_d\n",
    "                        else:\n",
    "                            features[qid][doc_id][8] = len_d\n",
    "                except KeyError:\n",
    "                    pass\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURES_FILE = \"data/features_qd_d.txt\"  # CHANGE TO WANTED FILE AND CHANGE get_features() IF NEEDED\n",
    "\n",
    "train_X, train_y, qids, doc_ids = load_features(FEATURES_FILE)\n",
    "\n",
    "def ftread(fpath):\n",
    "    features = {}\n",
    "    with open(fpath, 'r') as ft:\n",
    "        for line in ft.readlines():\n",
    "            linedata = line.split(' ')\n",
    "            qid = linedata[1]\n",
    "            docid = linedata[2]\n",
    "            features[docid] = {}\n",
    "            feats = linedata[3:]\n",
    "            for feat in feats:\n",
    "                ftdata = feat.split(':')\n",
    "                features[docid][float(ftdata[0])] = float(ftdata[1].strip('\\n'))\n",
    "    return features\n",
    "\n",
    "features = ftread(FEATURES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model\n",
    "\n",
    "Set `max_depth` roughly to the square root of the number features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "ltr = PointWiseLTRModel(clf)\n",
    "ltr._train(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying model on unseen queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY2_FILE = \"data/queries2.txt\"\n",
    "OUTPUT_FILE = \"data/ltr_kaggle.txt\"\n",
    "TOP_DOCS = 20  # this many top docs to write to output file\n",
    "NUM_FEAT = 8   # change this if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queries2 = load_queries(QUERY2_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply model and write results to output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing values for feature 'title & BM25' . . .\n",
      "Query 'identifying spider bites'\n",
      "Query 'history of orcas island'\n",
      "Query 'tooth abscess'\n",
      "Query 'barrett's esophagus'\n",
      "Query 'teddy bears'\n",
      "Query 'patron saint of mental illness'\n",
      "Query 'holes by louis sachar'\n",
      "Query 'hip roof'\n",
      "Query 'carpenter bee'\n",
      "Query 'the american revolutionary'\n",
      "Query 'folk remedies sore throat'\n",
      "Query 'balding cure'\n",
      "Query 'evidence for evolution'\n",
      "Query 'tribe formerly living in alabama'\n",
      "Query 'F5 tornado'\n",
      "Query 'symptoms of heart attack'\n",
      "Query 'feliz navidad lyrics'\n",
      "Query 'benefits of running'\n",
      "Query 'marshall county schools'\n",
      "Query 'sun tzu'\n",
      "Query 'halloween activities for middle school'\n",
      "Query 'dreams interpretation'\n",
      "Query 'wilson's disease'\n",
      "Query 'golf instruction'\n",
      "Query 'uss cole'\n",
      "Query 'how has african american music influence history'\n",
      "Query 'bewitched cast'\n",
      "Query 'mister rogers'\n",
      "Query 'game theory'\n",
      "Query 'view my internet history'\n",
      "Query 'ketogenic diet'\n",
      "Query 'nasa interplanetary missions'\n",
      "Query 'hayrides in pa'\n",
      "Query 'where to find morel mushrooms'\n",
      "Query 'magnesium rich foods'\n",
      "Query 'common schizophrenia drugs'\n",
      "Query 'carotid cavernous fistula treatment'\n",
      "Query 'fidel castro'\n",
      "Query 'benefits of yoga'\n",
      "Query 'norway spruce'\n",
      "Query 'sangre de cristo mountains'\n",
      "Query 'history of the electronic medical record'\n",
      "Query 'educational advantages of social networking sites'\n",
      "Query 'flowering plants'\n",
      "Query 'how to tie a windsor knot'\n",
      "Query 'recycling lead acid batteries'\n",
      "Query 'altitude sickness'\n",
      "Query 'medical care and jehovah's witnesses'\n",
      "Query 'pink slime in ground beef'\n",
      "Query 'how to find the mean'\n",
      "\n",
      "Computing values for feature 'title & LM' . . .\n",
      "Query 'identifying spider bites'\n",
      "Query 'history of orcas island'\n",
      "Query 'tooth abscess'\n",
      "Query 'barrett's esophagus'\n",
      "Query 'teddy bears'\n",
      "Query 'patron saint of mental illness'\n",
      "Query 'holes by louis sachar'\n",
      "Query 'hip roof'\n",
      "Query 'carpenter bee'\n",
      "Query 'the american revolutionary'\n",
      "Query 'folk remedies sore throat'\n",
      "Query 'balding cure'\n",
      "Query 'evidence for evolution'\n",
      "Query 'tribe formerly living in alabama'\n",
      "Query 'F5 tornado'\n",
      "Query 'symptoms of heart attack'\n",
      "Query 'feliz navidad lyrics'\n",
      "Query 'benefits of running'\n",
      "Query 'marshall county schools'\n",
      "Query 'sun tzu'\n",
      "Query 'halloween activities for middle school'\n",
      "Query 'dreams interpretation'\n",
      "Query 'wilson's disease'\n",
      "Query 'golf instruction'\n",
      "Query 'uss cole'\n",
      "Query 'how has african american music influence history'\n",
      "Query 'bewitched cast'\n",
      "Query 'mister rogers'\n",
      "Query 'game theory'\n",
      "Query 'view my internet history'\n",
      "Query 'ketogenic diet'\n",
      "Query 'nasa interplanetary missions'\n",
      "Query 'hayrides in pa'\n",
      "Query 'where to find morel mushrooms'\n",
      "Query 'magnesium rich foods'\n",
      "Query 'common schizophrenia drugs'\n",
      "Query 'carotid cavernous fistula treatment'\n",
      "Query 'fidel castro'\n",
      "Query 'benefits of yoga'\n",
      "Query 'norway spruce'\n",
      "Query 'sangre de cristo mountains'\n",
      "Query 'history of the electronic medical record'\n",
      "Query 'educational advantages of social networking sites'\n",
      "Query 'flowering plants'\n",
      "Query 'how to tie a windsor knot'\n",
      "Query 'recycling lead acid batteries'\n",
      "Query 'altitude sickness'\n",
      "Query 'medical care and jehovah's witnesses'\n",
      "Query 'pink slime in ground beef'\n",
      "Query 'how to find the mean'\n",
      "\n",
      "Computing values for feature 'content & BM25' . . .\n",
      "Query 'identifying spider bites'\n",
      "Query 'history of orcas island'\n",
      "Query 'tooth abscess'\n",
      "Query 'barrett's esophagus'\n",
      "Query 'teddy bears'\n",
      "Query 'patron saint of mental illness'\n",
      "Query 'holes by louis sachar'\n",
      "Query 'hip roof'\n",
      "Query 'carpenter bee'\n",
      "Query 'the american revolutionary'\n",
      "Query 'folk remedies sore throat'\n",
      "Query 'balding cure'\n",
      "Query 'evidence for evolution'\n",
      "Query 'tribe formerly living in alabama'\n",
      "Query 'F5 tornado'\n",
      "Query 'symptoms of heart attack'\n",
      "Query 'feliz navidad lyrics'\n",
      "Query 'benefits of running'\n",
      "Query 'marshall county schools'\n",
      "Query 'sun tzu'\n",
      "Query 'halloween activities for middle school'\n",
      "Query 'dreams interpretation'\n",
      "Query 'wilson's disease'\n",
      "Query 'golf instruction'\n",
      "Query 'uss cole'\n",
      "Query 'how has african american music influence history'\n",
      "Query 'bewitched cast'\n",
      "Query 'mister rogers'\n",
      "Query 'game theory'\n",
      "Query 'view my internet history'\n",
      "Query 'ketogenic diet'\n",
      "Query 'nasa interplanetary missions'\n",
      "Query 'hayrides in pa'\n",
      "Query 'where to find morel mushrooms'\n",
      "Query 'magnesium rich foods'\n",
      "Query 'common schizophrenia drugs'\n",
      "Query 'carotid cavernous fistula treatment'\n",
      "Query 'fidel castro'\n",
      "Query 'benefits of yoga'\n",
      "Query 'norway spruce'\n",
      "Query 'sangre de cristo mountains'\n",
      "Query 'history of the electronic medical record'\n",
      "Query 'educational advantages of social networking sites'\n",
      "Query 'flowering plants'\n",
      "Query 'how to tie a windsor knot'\n",
      "Query 'recycling lead acid batteries'\n",
      "Query 'altitude sickness'\n",
      "Query 'medical care and jehovah's witnesses'\n",
      "Query 'pink slime in ground beef'\n",
      "Query 'how to find the mean'\n",
      "\n",
      "Computing values for feature 'content & LM' . . .\n",
      "Query 'identifying spider bites'\n",
      "Query 'history of orcas island'\n",
      "Query 'tooth abscess'\n",
      "Query 'barrett's esophagus'\n",
      "Query 'teddy bears'\n",
      "Query 'patron saint of mental illness'\n",
      "Query 'holes by louis sachar'\n",
      "Query 'hip roof'\n",
      "Query 'carpenter bee'\n",
      "Query 'the american revolutionary'\n",
      "Query 'folk remedies sore throat'\n",
      "Query 'balding cure'\n",
      "Query 'evidence for evolution'\n",
      "Query 'tribe formerly living in alabama'\n",
      "Query 'F5 tornado'\n",
      "Query 'symptoms of heart attack'\n",
      "Query 'feliz navidad lyrics'\n",
      "Query 'benefits of running'\n",
      "Query 'marshall county schools'\n",
      "Query 'sun tzu'\n",
      "Query 'halloween activities for middle school'\n",
      "Query 'dreams interpretation'\n",
      "Query 'wilson's disease'\n",
      "Query 'golf instruction'\n",
      "Query 'uss cole'\n",
      "Query 'how has african american music influence history'\n",
      "Query 'bewitched cast'\n",
      "Query 'mister rogers'\n",
      "Query 'game theory'\n",
      "Query 'view my internet history'\n",
      "Query 'ketogenic diet'\n",
      "Query 'nasa interplanetary missions'\n",
      "Query 'hayrides in pa'\n",
      "Query 'where to find morel mushrooms'\n",
      "Query 'magnesium rich foods'\n",
      "Query 'common schizophrenia drugs'\n",
      "Query 'carotid cavernous fistula treatment'\n",
      "Query 'fidel castro'\n",
      "Query 'benefits of yoga'\n",
      "Query 'norway spruce'\n",
      "Query 'sangre de cristo mountains'\n",
      "Query 'history of the electronic medical record'\n",
      "Query 'educational advantages of social networking sites'\n",
      "Query 'flowering plants'\n",
      "Query 'how to tie a windsor knot'\n",
      "Query 'recycling lead acid batteries'\n",
      "Query 'altitude sickness'\n",
      "Query 'medical care and jehovah's witnesses'\n",
      "Query 'pink slime in ground beef'\n",
      "Query 'how to find the mean'\n",
      "\n",
      "Computing values for feature 'anchors & BM25' . . .\n",
      "Query 'identifying spider bites'\n",
      "Query 'history of orcas island'\n",
      "Query 'tooth abscess'\n",
      "Query 'barrett's esophagus'\n",
      "Query 'teddy bears'\n",
      "Query 'patron saint of mental illness'\n",
      "Query 'holes by louis sachar'\n",
      "Query 'hip roof'\n",
      "Query 'carpenter bee'\n",
      "Query 'the american revolutionary'\n",
      "Query 'folk remedies sore throat'\n",
      "Query 'balding cure'\n",
      "Query 'evidence for evolution'\n",
      "Query 'tribe formerly living in alabama'\n",
      "Query 'F5 tornado'\n",
      "Query 'symptoms of heart attack'\n",
      "Query 'feliz navidad lyrics'\n",
      "Query 'benefits of running'\n",
      "Query 'marshall county schools'\n",
      "Query 'sun tzu'\n",
      "Query 'halloween activities for middle school'\n",
      "Query 'dreams interpretation'\n",
      "Query 'wilson's disease'\n",
      "Query 'golf instruction'\n",
      "Query 'uss cole'\n",
      "Query 'how has african american music influence history'\n",
      "Query 'bewitched cast'\n",
      "Query 'mister rogers'\n",
      "Query 'game theory'\n",
      "Query 'view my internet history'\n",
      "Query 'ketogenic diet'\n",
      "Query 'nasa interplanetary missions'\n",
      "Query 'hayrides in pa'\n",
      "Query 'where to find morel mushrooms'\n",
      "Query 'magnesium rich foods'\n",
      "Query 'common schizophrenia drugs'\n",
      "Query 'carotid cavernous fistula treatment'\n",
      "Query 'fidel castro'\n",
      "Query 'benefits of yoga'\n",
      "Query 'norway spruce'\n",
      "Query 'sangre de cristo mountains'\n",
      "Query 'history of the electronic medical record'\n",
      "Query 'educational advantages of social networking sites'\n",
      "Query 'flowering plants'\n",
      "Query 'how to tie a windsor knot'\n",
      "Query 'recycling lead acid batteries'\n",
      "Query 'altitude sickness'\n",
      "Query 'medical care and jehovah's witnesses'\n",
      "Query 'pink slime in ground beef'\n",
      "Query 'how to find the mean'\n",
      "\n",
      "Computing values for feature 'anchors & LM' . . .\n",
      "Query 'identifying spider bites'\n",
      "Query 'history of orcas island'\n",
      "Query 'tooth abscess'\n",
      "Query 'barrett's esophagus'\n",
      "Query 'teddy bears'\n",
      "Query 'patron saint of mental illness'\n",
      "Query 'holes by louis sachar'\n",
      "Query 'hip roof'\n",
      "Query 'carpenter bee'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 'the american revolutionary'\n",
      "Query 'folk remedies sore throat'\n",
      "Query 'balding cure'\n",
      "Query 'evidence for evolution'\n",
      "Query 'tribe formerly living in alabama'\n",
      "Query 'F5 tornado'\n",
      "Query 'symptoms of heart attack'\n",
      "Query 'feliz navidad lyrics'\n",
      "Query 'benefits of running'\n",
      "Query 'marshall county schools'\n",
      "Query 'sun tzu'\n",
      "Query 'halloween activities for middle school'\n",
      "Query 'dreams interpretation'\n",
      "Query 'wilson's disease'\n",
      "Query 'golf instruction'\n",
      "Query 'uss cole'\n",
      "Query 'how has african american music influence history'\n",
      "Query 'bewitched cast'\n",
      "Query 'mister rogers'\n",
      "Query 'game theory'\n",
      "Query 'view my internet history'\n",
      "Query 'ketogenic diet'\n",
      "Query 'nasa interplanetary missions'\n",
      "Query 'hayrides in pa'\n",
      "Query 'where to find morel mushrooms'\n",
      "Query 'magnesium rich foods'\n",
      "Query 'common schizophrenia drugs'\n",
      "Query 'carotid cavernous fistula treatment'\n",
      "Query 'fidel castro'\n",
      "Query 'benefits of yoga'\n",
      "Query 'norway spruce'\n",
      "Query 'sangre de cristo mountains'\n",
      "Query 'history of the electronic medical record'\n",
      "Query 'educational advantages of social networking sites'\n",
      "Query 'flowering plants'\n",
      "Query 'how to tie a windsor knot'\n",
      "Query 'recycling lead acid batteries'\n",
      "Query 'altitude sickness'\n",
      "Query 'medical care and jehovah's witnesses'\n",
      "Query 'pink slime in ground beef'\n",
      "Query 'how to find the mean'\n",
      "Computing values for additional document features . . .\n"
     ]
    }
   ],
   "source": [
    "# output_format = \"trec\"\n",
    "output_format = \"whydoweneedthis\"\n",
    "# Get feature vectors\n",
    "feats = get_features(queries2)\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as fout:\n",
    "    fout.write(\"QueryId,DocumentId\\n\")\n",
    "    for qid, query in sorted(queries2.items()):            \n",
    "        # Convert into the format required by the `PointWiseLTRModel` class\n",
    "        # and deal with missing feature values\n",
    "        doc_fts = []\n",
    "        doc_ids = []\n",
    "        \n",
    "        for doc_id, feat in features.items():\n",
    "            for fid in range(1, NUM_FEAT + 1):\n",
    "                if fid not in feat:\n",
    "                    feat[fid] = -1\n",
    "            try: \n",
    "                doc_fts.append(np.array([float(val) for fid, val in sorted(feat.items())]))\n",
    "            except TypeError:\n",
    "                print(feat.items())\n",
    "            doc_ids.append(doc_id)\n",
    "        \n",
    "        # Get ranking\n",
    "        r = ltr.rank(doc_fts, doc_ids)    \n",
    "        # Write the results to file\n",
    "        rank = 1\n",
    "        for doc_id, score in r:\n",
    "            if rank <= TOP_DOCS:\n",
    "                if output_format == \"trec\":\n",
    "                    fout.write((\"\\t\".join([\"{}\"] * 6) + \"\\n\").format(qid, \"Q0\", doc_id, str(rank),\n",
    "                                                                 str(score), \"A3_3_Baseline\"))\n",
    "                else: \n",
    "                    fout.write(qid + \",\" + doc_id + \"\\n\")                            \n",
    "            rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
